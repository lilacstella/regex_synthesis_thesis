%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  Template code for the Undergraduate Research Scholars thesis program starting, updated by Undergraduate Research Scholars program staff. Version 6.0. Last Updated: Fall 2024
%  Modified by Tawfik Hussein from the template code for TAMU Theses and Dissertations starting Spring 2018, authored by Sean Zachary Roberson. Version 3.17.09.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           SECTION III: RESULTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%_________________(0)______________
% Do not modify. This is the page heading

% THIS LINE PUTS "CHAPTER III RESULTS" AT THE TOP OF THE PAGE, BOLD-FACED AND 14-PT
\chapter{EVALUATION METRICS}

\counterwithout{table}{chapter} % Prevents the table count from resetting in each chapter

\indent\indent To evaluate the performance of the synthesis methods explored in this thesis—AlphaRegex, the L* algorithm, and large language models—we adapted a benchmark suite of 25 regular expression problems originally proposed in the AlphaRegex paper \cite{lee_2016_synthesizing}. These tasks include string containment, structural alternation, and sequence matching. As shown in Figure~\ref{fig:benchmark-example}, each benchmark begins with a natural language description of the regex problem, followed by a set of positive and negative examples. The benchmarks are loosely organized by increasing difficulty.

\begin{figure}[h!]
	\centering
	Example of a benchmark file used in the evaluation process.
	\begin{verbatim}
	w contains the substring abab
	++
	abab
	XababX
	XXababXX
	--
	a
	b
	XX
	XXX
	XXXa
	XaXX
	bXXX
	XXbX
	\end{verbatim}
	\captionsetup{justification=centering}
	\caption{Example of a benchmark task to find a string that contains "ab". The specificiation starts with a natural language description, followed by positive and negative examples. The "X" in the individual examples represent that this example exists with any character in the alphabet.}
	\label{fig:benchmark-example}
\end{figure}

\indent\indent As the different algorithms require different types of input, the evaluation process was tailored accordingly. ChatGPT and AlphaRegex were provided with the benchmark file in its entirety, including the natural language description and examples. For the L* algorithm, the natural language description was interpreted by a human to manually construct the required membership and equivalence queries.

\section{Metrics}

\indent\indent To comprehensively compare synthesis approaches, we defined three categories of evaluation metrics:
Correctness was evaluated by determining whether a solution satisfied all positive examples and rejected all negative examples. Final validation was performed via human inspection to account for edge cases or oversimplified expressions. Efficiency metrics included the number of states explored for AlphaRegex, the number of membership and equivalence queries made for L*, and the wall-clock time required to generate results for all three methods. Complexity was assessed in three ways: total character count, the number of operators, and a subjective readability score ranging from 1 (unreadable) to 5 (clean and intuitive).

\section{Experimental Setup}

\indent\indent We implemented AlphaRegex and L* in Python and the code is readily available as seen in Appendix~A. LLM queries were issued through the OpenAI ChatGPT-4 API (March 2025 snapshot).


\chapter{RESULTS AND DISCUSSION}
\section{Quantitative Results}

\indent\indent The table below summarizes the performance of each method on the 25 benchmark tasks. Correctness reflects the number of benchmarks where the generated regex matched all positive and negative examples. Efficiency and complexity metrics are averaged over all correct results.

\begin{table}[h!]
\centering
\label{tab:alpha_regex_performance_times}
\caption{Performance comparison of regex synthesis methods using wall-clock time. The numbers that were skipped were unable to find a solution within a reasonable time constraint (10,000 seconds). "Pos" and "Neg" represent the number of positive and negative examples. "Full," "No Apr," and "No Rd" denote the time (in seconds) for the full process, without over-approximation, and without redundancy removal, respectively.}
\begin{tabular}{|c|p{5cm}|c|c|c|c|c|p{2.5cm}|}
\hline

\textbf{No} & \textbf{Description} & \textbf{Pos} & \textbf{Neg}  & \textbf{Full} & \textbf{No Apr} & \textbf{No Rd} & \textbf{Output} \\
\hline
1 & Starts with a & 3 & 3 & 0.0 & 0.0 & 0.0 & a.* \\
2 & Ends with ab & 3 & 6 & 0.0 & 0.1 & 0.0 & .*ab \\
3 & Contains the substring abab & 3 & 7 & 1.4 & 10.6 & 1.1 & - \\
4 & Begins with b and ends with a & 3 & 5 & 0.0 & 0.0 & 0.0 & b.*a \\
5 & Length is at least 3 and the 3rd symbol is a & 3 & 4 & 0.0 & 0.0 & 0.0 & ..a.* \\
6 & Length is a multiple of 3 & 2 & 3 & 0.1 & 0.1 & 0.1 & (...)* \\
8 & Even number of a's & 7 & 7 & 0.1 & 1.0 & 0.2 & (b*(ab*a)*)* \\
11 & Each a in w is followed by at least one b & 7 & 6 & 0.0 & 0.0 & 0.0 & (b*(ab)*)* \\
15 & Length greater than 1 & 3 & 2 & 0.0 & 0.0 & 0.0 & ..*. \\
\hline
\end{tabular}
\end{table}

\begin{table}[h!]
	\centering
	\label{tab:alpha_regex_performance_s}
	\caption{Summary of the 25 benchmarks, including the number of positive and negative examples, along with the expected human-generated regex solutions.}
	\begin{tabular}{|c|p{5cm}|c|c|p{2.5cm}|}
	\hline
	\textbf{No} & \textbf{Description} & \textbf{Pos} & \textbf{Neg}  & \textbf{States explored} & \textbf{Output} \\
	\hline
	1 & Starts with a & 3 & 3 & a.* \\
	2 & Ends with ab & 3 & 6 & 0.0 & 0.1 & 0.0 & .*ab \\
	3 & Contains the substring abab & 3 & 7 & 1.4 & 10.6 & 1.1 & - \\
	4 & Begins with b and ends with a & 3 & 5 & 0.0 & 0.0 & 0.0 & b.*a \\
	5 & Length is at least 3 and the 3rd symbol is a & 3 & 4 & 0.0 & 0.0 & 0.0 & ..a.* \\
	6 & Length is a multiple of 3 & 2 & 3 & 0.1 & 0.1 & 0.1 & (...)* \\
	7 & Number of a's is divisible by 3 & 8 & 7 & 9.5 & 238.4 & 36.9 & - \\
	8 & Even number of a's & 7 & 7 & 0.1 & 1.0 & 0.2 & (b*(ab*a)*)* \\
	9 & Fifth symbol from the right is b & 3 & 3 & 9.0 & 56.3 & 14.3 & - \\
	10 & Alternating a and b & 9 & 8 & 1.7 & 19.7 & 3.5 & - \\
	11 & Each a in w is followed by at least one b & 7 & 6 & 0.0 & 0.0 & 0.0 & (b*(ab)*)* \\
	12 & a$^n$b$^m$ where $n \geq 3$ and $m$ is even. & 6 & 5 & 0.2 & 1.0 & 0.0 & - \\
	13 & Have at most two a's & 7 & 5 & 1.4 & 9.5 & 2.3 & - \\
	14 & Start with a and have odd length or start with b and have even length & 5 & 5 & 16.5 & 771.9 & 14.7 & - \\
	15 & Length greater than 1 & 3 & 2 & 0.0 & 0.0 & 0.0 & ..*. \\
	16 & Does not end with ab & 8 & 3 & 17.8 & 302.1 & 15.2 & - \\
	17 & Contain at least one a and at most one b & 6 & 9 & 2.7 & 33.5 & 7.7 & - \\
	18 & At least two occurrences of b between any two occurrences of a & 7 & 7 & 0.2 & 0.4 & 0.2 & - \\
	19 & Does not contain baa as a substring & 8 & 4 & 0.1 & 0.1 & 0.1 & - \\
	20 & Every odd position is b & 6 & 9 & 3.6 & 10.5 & 5.0 & - \\
	21 & Consecutive pair aa appears exactly once & 4 & 4 & 1.0 & 16.1 & 2.9 & - \\
	22 & Length $\ge 2$ and does not end with ba & 9 & 4 & 57.2 & 4248.0 & 75.3 & - \\
	23 & Even number of a's and each a is followed by at least one b & 6 & 9 & 1.8 & 30.2 & 4.3 & - \\
	24 & All adjacent a's appear before any adjacent b's & - & - & - & - & - & - \\
	25 & At most one pair of consecutive b's & - & - & - & - & - & - \\
	\hline
	\multicolumn{2}{|c|}{\textbf{Average}} & - & - & 284.8 & 284.8 & 18.8 & -- \\
	\hline
	\end{tabular}
	\end{table}

\section{AlphaRegex Weight Analysis}

\indent\indent We experimented with three different weight configurations to observe how heuristic prioritization changes the generated output. Each configuration emphasizes different regex characteristics: minimal size, reduced use of \texttt{*}, and balanced weight. The results below illustrate how weights impact regex complexity and runtime.

In the release of the source codes, the weights are set to the default values. The weights are set to the following values:
#TODO 

\begin{table}[h!]
\centering
\caption{Example Benchmark: "Contains alternating 0 and 1"}
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Weight Profile} & \textbf{Time (s)} & \textbf{Correct} & \textbf{Regex Output} \\
\hline
Min-Length & 0.0 & No & -- \\
Star-Penalized & 0.0 & No & -- \\
Balanced & 0.0 & No & -- \\
\hline
\end{tabular}
\end{table}

\section{Qualitative Observations}

\indent\indent Beyond correctness, several differences emerged in the qualitative behavior of the three approaches:

\begin{itemize}
\item \textbf{AlphaRegex:} Tends to generate readable regex due to its greedy nature but struggles with deeper nesting or ambiguous patterns. Sensitive to weight tuning.
\item \textbf{L* Algorithm:} Provides minimal regex when guided by precise counterexamples. Relies heavily on teacher quality. Most effective with simple patterns.
\item \textbf{LLMs:} Generates regex quickly, often with impressive readability. However, it frequently overfits to examples or introduces syntax errors.
\end{itemize}

\section{Integration Synthesis}

\indent\indent Though not fully implemented, we explored ideas for combining models. One early prototype used ChatGPT to generate candidate regex, which were validated and refined by AlphaRegex. This semi-automated pipeline showed promise: even when the LLM failed to produce correct output directly, its regex often seeded AlphaRegex with promising starting points.

\begin{figure}[h!]
\centering
\fbox{\parbox{0.9\linewidth}{\centering \textbf{Pipeline:} LLM Suggestion $\rightarrow$ AlphaRegex Verification $\rightarrow$ Weight-Based Refinement}}
\caption{Illustration of Integration Synthesis Pipeline}
\end{figure}

\section{Discussion}

\subsection{Interpretation of Results}

\indent\indent While none of the methods achieved perfect correctness across the board, each demonstrated clear strengths. AlphaRegex proved transparent and tunable, L* offered principled guarantees when guided effectively, and LLMs showcased a fast and flexible interface for casual users.

\subsection{Trade-offs in Regex Synthesis}

\begin{itemize}
\item \textbf{Speed vs. Correctness:} LLMs were fastest but least reliable. AlphaRegex was slowest but most trustworthy under the right weights.
\item \textbf{Simplicity vs. Generalization:} L* produced minimal regex, but sometimes at the cost of capturing broad behavior.
\item \textbf{Readability vs. Verifiability:} AlphaRegex outputs were often easiest to verify manually. LLMs optimized readability at the cost of precision.
\end{itemize}

\subsection{Lessons for Broader Synthesis}

\indent\indent These findings may generalize to other synthesis tasks. Combining heuristic, procedural, and neural paradigms may help mitigate the weaknesses of each and play to their complementary strengths. The success of LLM seeding also suggests a powerful role for neural priors in symbolic search.

\vspace{2em}

